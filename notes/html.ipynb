{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text from HTML file\n",
    "\n",
    "There are lots of data sources from which we might want to extract information, such as initial public offerings for various companies. E.g., [Tesla's IPO prospectus](https://www.sec.gov/Archives/edgar/data/1318605/000119312510017054/ds1.htm). One can imagine trying to mine such documents in an effort to predict which IPOs will do poorly or well.\n",
    "\n",
    "HTML has both text as well as so-called markup like `<b>`, which is used to specify formatting information.\n",
    "\n",
    "We will use the well-known [Beautiful soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) Python library to extract text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main script\n",
    "\n",
    "Our main program accepts a file name parameter from the commandline, opens it, gets its text, converts the HTML to text, and close the file. Our first attempt, after looking at the documentation, might be the following (file `ipo-text.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S-1\n",
      "1\n",
      "ds1.htm\n",
      "REGISTRATION STATEMENT ON FORM S-1\n",
      "\n",
      "\n",
      "Registration Statement on Form S-1\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "As filed with the Securities and Exchange Commission on January 29, 2010 \n",
      "Registration No. 333-                \n",
      "      UNITED STATES  SECURITIES AND EXCHANGE COMMISSION  Washington, D.C. 20549  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"../data/TeslaIPO.html\", \"r\") as f:\n",
    "    html_text = f.read()\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "text = soup.get_text()\n",
    "print(text[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy up\n",
    "\n",
    "Let's improve our program by creating a function to extract text from HTML text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html2text(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, our main program looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S-1\n",
      "1\n",
      "ds1.htm\n",
      "REGISTRATION STATEMENT ON FORM S-1\n",
      "\n",
      "\n",
      "Registration Statement on Form S-1\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "As filed with the Securities and Exchange Commission on January 29, 2010 \n",
      "Registration No. 333-                \n",
      "      UNITED STATES  SECURITIES AND EXCHANGE COMMISSION  Washington, D.C. 20549      FORM S-1 \n",
      " REGISTRATION STATEMENT  UNDER  THE SECURITIES ACT OF 1933      Tesla Motors, Inc.  (Exact name of Registrant as\n",
      "specified in its charter)       \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Delaware\n",
      " \n",
      "3711\n",
      " \n",
      "91-2197729\n",
      "\n",
      " (State or other jurisdiction of incorporation or organization)\n",
      " \n",
      " (Primary Standard Industrial Classification Code Number)\n",
      " \n",
      " (I.R.S. Employer Identification Number) 3500 Deer Creek Road\n",
      " Palo Alto, California 94304  (650) 413-4000  (Address, including zip code, and telephone number,\n",
      "including area code, of Registrants principal executive offices)      Elon Musk \n",
      " Chief Executive Officer  Tesla Motors, Inc.  3500 Deer Creek Road  Palo Alto, California 94304  (650) 413-4000  (Name, address, inclu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html2text(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "with open(\"../data/TeslaIPO.html\", \"r\") as f:\n",
    "    html_text = f.read()\n",
    "text = html2text(html_text)\n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Copy that program into a Python file called `ipo-text.py` and run it from the command line. You will notice that there is weird stuff in the output like: `Registrant<U+0092>s`. That 92 is the character code, in hexadecimal, for the fancy single quote: `’`. You will have to download the [TeslaIPO.html](https://github.com/parrt/msds692/blob/master/data/TeslaIPO.html) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting non-ASCII char\n",
    "\n",
    "We should clean up the text extracted from the HTML so that the non-ASCII characters are stripped or converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S-1\n",
      "1\n",
      "ds1.htm\n",
      "REGISTRATION STATEMENT ON FORM S-1\n",
      "\n",
      "\n",
      "Registration Statement on Form S-1\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "As filed with the Securities and Exchange Commission on January 29, 2010 \n",
      "Registration No.333-\n",
      "   UNITED STATES  SECURITIES AND EXCHANGE COMMISSION  Washington, D.C. 20549    FORM S-1 \n",
      " REGISTR\n"
     ]
    }
   ],
   "source": [
    "text = [c for c in text if ord(c)<=127]\n",
    "text = ''.join(text)\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Print out the number of unique words in the document (split on whitespace). For Tesla's IPO, I get 10602 unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10602"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Create a histogram using a dictionary that maps words to the word count. I use `defaultdict(int)` to define my histogram; very convenient. Sort and print out the list of tuples from `items()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 6455), ('of', 5762), ('and', 4265), ('to', 3814), ('our', 2502), ('in', 2380), ('a', 1689), ('we', 1280), ('for', 1264), ('or', 1194), ('as', 965), ('that', 862), ('be', 838), ('on', 739), ('with', 734), ('are', 701), ('We', 676), ('have', 648), ('will', 642), ('by', 616), ('stock', 606), ('is', 588), ('an', 575), ('shares', 568), ('not', 536), ('may', 531), ('Tesla', 529), ('from', 524), ('which', 523), ('The', 520), ('electric', 436), ('this', 418), ('at', 411), ('such', 396), ('common', 393), ('any', 374), ('vehicles', 373), ('other', 370), ('$', 362), ('million', 341), ('vehicle', 336), ('In', 335), ('under', 334), ('these', 319), ('Model', 309), ('ended', 307), ('sales', 293), ('December31,', 280), ('us', 275), (')', 263), ('2008', 254), ('2009,', 251), ('per', 249), ('financial', 247), ('convertible', 245), ('could', 240), ('United', 239), ('Table', 231), ('has', 231), ('Contents', 230), ('Roadster', 228), ('2009', 227), ('development', 224), ('during', 224), ('all', 223\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "counts = defaultdict(int)\n",
    "for w in text.split():\n",
    "    counts[w] += 1\n",
    "histo = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(str(histo)[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now, create the histogram the easy way using `Counter`. If you print that object, it will show you `Counter({'the': 6483, 'of': 5788, 'and': 4274, ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 6455, 'of': 5762, 'and': 4265, 'to': 3814, 'our': 2502, 'in': 2380, 'a': 1689, 'we': 1280, 'for': 1264, 'or': 1194, 'as': 965, 'that': 862, 'be': 838, 'on': 739, 'with': 734, 'are': 701, 'We': 676, 'have': 648, 'will': 642, 'by': 616, 'stock': 606, 'is': 588, 'an': 575, 'shares': 568, 'not': 536, 'may': 531, 'Tesla': 529, 'from': 524, 'which': 523, 'The': 520, 'electric': 436, 'this': 418, 'at': 411, 'such': 396, 'common': 393, 'any': 374, 'vehicles': 373, 'other': 370, '$': 362, 'million': 341, 'vehicle': 336, 'In': 335, 'under': 334, 'these': 319, 'Model': 309, 'ended': 307, 'sales': 293, 'December31,': 280, 'us': 275, ')': 263, '2008': 254, '2009,': 251, 'per': 249, 'financial': 247, 'convertible': 245, 'could': 240, 'United': 239, 'Table': 231, 'has': 231, 'Contents': 230, 'Roadster': 228, '2009': 227, 'development': 224, 'during': 224, 'all': 223, 'September30,': 220, 'S': 218, 'value': 217, 'Our': 217, 'into': 209, 'price': 203, 'preferred': 203, 'upon': 201, 'bat\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(text.split())\n",
    "print(str(counts)[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stripping char beyond 255 from commandline\n",
    "\n",
    "If there are characters within the file that are non-ASCII and larger than 255, we can convert the file using the command line. Here's a simple version of the problem I put into file `/tmp/foo.html`:\n",
    "\n",
    "```html\n",
    "<html>\n",
    "<body>\n",
    "གྷ\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "I deliberately injected a Unicode code point > 255, which requires two bytes to store.  Most of the characters require just one byte. Here is first part of file:\n",
    "\n",
    "```bash\n",
    "$ od -c -t xC /tmp/t.html\n",
    "0000000    <   h   t   m   l   >  \\n   <   b   o   d   y   >  \\n   གྷ  **\n",
    "           3c  68  74  6d  6c  3e  0a  3c  62  6f  64  79  3e  0a  e0  bd\n",
    "...\n",
    "```           \n",
    "\n",
    "Here is how you could strip any non-one-byte characters from the file before processing:\n",
    "\n",
    "```bash\n",
    "$ iconv -c -f utf-8 -t ascii /tmp/foo.html \n",
    "<html>\n",
    "<body>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
